# Day 4: Physics Wallah Active Recall Tutor - LinkedIn Post

---

ğŸ“ **Day 4 of #10DaysofAIVoiceAgents Challenge: Built an Active Recall Tutor with 3 Distinct AI Voices!** ğŸ¤

I'm excited to share my latest project from the Murf AI Voice Agents Challenge - a **Physics Wallah-inspired Active Recall Tutor** that intelligently switches between THREE different voices in a single conversation! ğŸš€

**ğŸ¯ What Makes This Special?**

Instead of a single monotone AI tutor, I've implemented an adaptive learning system that uses different voices for different learning modes:

ğŸ—£ï¸ **Matthew** - Learn Mode (Warm, explanatory voice)
When you ask "Explain variables to me", Matthew teaches concepts with clear explanations and examples.

ğŸ—£ï¸ **Alicia** - Quiz Mode (Energetic, challenging voice)  
Say "Quiz me on loops" and Alicia takes over, testing your knowledge with thought-provoking questions.

ğŸ—£ï¸ **Ken** - Teach Back Mode (Encouraging, reflective voice)
Request "Let me teach you about functions" and Ken listens as you explain concepts back, reinforcing your understanding.

**ğŸ”„ Seamless Voice Handoffs in Real-Time**

The magic happens with LiveKit's agent handoff system - the AI automatically detects your intent and switches between learning modes WITHOUT leaving the room. It's like having three specialized tutors working together!

**ğŸ› ï¸ Tech Stack:**
- ğŸ™ï¸ Murf Falcon TTS (Matthew, Alicia, Ken voices) - fastest voice synthesis API
- ğŸ¤– Google Gemini 2.5 Flash - conversational AI
- ğŸ§ Deepgram Nova-3 STT - real-time speech recognition  
- ğŸŒ LiveKit - multi-agent orchestration & handoffs
- âš¡ Next.js + React - real-time UI with status indicators

**ğŸ’¡ The Active Recall Method:**

This isn't just another chatbot - it's based on proven learning science:
1. **Learn** - Absorb new concepts with guided explanations
2. **Quiz** - Test your understanding immediately  
3. **Teach Back** - Explain concepts in your own words (the ultimate retention test!)

Studies show active recall improves retention by 50%+ compared to passive learning!

**ğŸ¨ Enhanced User Experience:**

Added real-time status indicators that show when the agent is:
- ğŸ’­ Thinking (yellow bounce animation)
- ğŸ—£ï¸ Speaking (green pulse)
- ğŸ‘‚ Listening (blue pulse)
- âœ… Ready (gray)

**ğŸ”¥ Key Challenges Solved:**

1. Implementing LiveKit's multi-agent handoff system with custom function tools
2. Overriding TTS plugins per agent to maintain distinct voice identities
3. Preserving conversation context across voice transitions
4. Building smooth UI feedback for seamless learning experience
5. Managing 5 different AI concepts (variables, loops, functions, conditionals, data types)

**ğŸ“Š The Results:**

âœ… Three distinct voices working harmoniously in one room
âœ… Instant handoffs triggered by natural language
âœ… Zero interruption in learning flow
âœ… Real-time visual feedback on agent state
âœ… Personalized learning path based on student needs

This project combines the best of AI voice technology with educational psychology principles. The future of personalized learning is here - and it sounds incredible! ğŸ¯

Huge thanks to @Murf AI for the #MurfAIVoiceAgentsChallenge and making this powerful technology accessible to developers! ğŸ™Œ

**Tech Details:**
- GitHub: [Your Repo Link]
- Demo Video: [Coming Soon]
- Live: localhost:3001

What learning mode would YOU try first? Drop a comment below! ğŸ‘‡

#AI #EdTech #VoiceAI #MachineLearning #LiveKit #NextJS #Python #Education #ActiveRecall #PhysicsWallah #Innovation #DeveloperCommunity #BuildInPublic

---

**Character Count: 2,947** âœ… (Under 3000 limit)
